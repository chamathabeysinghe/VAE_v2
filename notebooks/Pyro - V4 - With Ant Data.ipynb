{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import visdom\n",
    "\n",
    "import pyro\n",
    "import pyro.contrib.examples.multi_mnist as multi_mnist\n",
    "import pyro.optim as optim\n",
    "import pyro.poutine as poutine\n",
    "from components.AIR import AIR, latents_to_tensor\n",
    "from pyro.contrib.examples.util import get_data_directory\n",
    "from pyro.infer import SVI, JitTraceGraph_ELBO, TraceGraph_ELBO\n",
    "from utils.viz import draw_many, tensor_to_objs\n",
    "from utils.visualizer import plot_mnist_sample\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_accuracy(X, true_counts, air, batch_size):\n",
    "    assert X.size(0) == true_counts.size(0), 'Size mismatch.'\n",
    "    assert X.size(0) % batch_size == 0, 'Input size must be multiple of batch_size.'\n",
    "    counts = torch.LongTensor(3, 4).zero_()\n",
    "    error_latents = []\n",
    "    error_indicators = []\n",
    "\n",
    "    def count_vec_to_mat(vec, max_index):\n",
    "        out = torch.LongTensor(vec.size(0), max_index + 1).zero_()\n",
    "        out.scatter_(1, vec.type(torch.LongTensor).view(vec.size(0), 1), 1)\n",
    "        return out\n",
    "\n",
    "    for i in range(X.size(0) // batch_size):\n",
    "        X_batch = X[i * batch_size:(i + 1) * batch_size]\n",
    "        true_counts_batch = true_counts[i * batch_size:(i + 1) * batch_size]\n",
    "        z_where, z_pres = air.guide(X_batch, batch_size)\n",
    "        inferred_counts = sum(z.cpu() for z in z_pres).squeeze().data\n",
    "        true_counts_m = count_vec_to_mat(true_counts_batch, 2)\n",
    "        inferred_counts_m = count_vec_to_mat(inferred_counts, 3)\n",
    "        counts += torch.mm(true_counts_m.t(), inferred_counts_m)\n",
    "        error_ind = 1 - (true_counts_batch == inferred_counts)\n",
    "        error_ix = error_ind.nonzero().squeeze()\n",
    "        error_latents.append(latents_to_tensor((z_where, z_pres)).index_select(0, error_ix))\n",
    "        error_indicators.append(error_ind)\n",
    "\n",
    "    acc = counts.diag().sum().float() / X.size(0)\n",
    "    error_indices = torch.cat(error_indicators).nonzero().squeeze()\n",
    "    if X.is_cuda:\n",
    "        error_indices = error_indices.cuda()\n",
    "    return acc, counts, torch.cat(error_latents), error_indices\n",
    "\n",
    "\n",
    "# Defines something like a truncated geometric. Like the geometric,\n",
    "# this has the property that there's a constant difference in log prob\n",
    "# between p(steps=n) and p(steps=n+1).\n",
    "def make_prior(k):\n",
    "    assert 0 < k <= 1\n",
    "    u = 1 / (1 + k + k**2 + k**3)\n",
    "    p0 = 1 - u\n",
    "    p1 = 1 - (k * u) / p0\n",
    "    p2 = 1 - (k**2 * u) / (p0 * p1)\n",
    "    trial_probs = [p0, p1, p2]\n",
    "    # dist = [1 - p0, p0 * (1 - p1), p0 * p1 * (1 - p2), p0 * p1 * p2]\n",
    "    # print(dist)\n",
    "    return lambda t: trial_probs[t]\n",
    "\n",
    "\n",
    "# Implements \"prior annealing\" as described in this blog post:\n",
    "# http://akosiorek.github.io/ml/2017/09/03/implementing-air.html\n",
    "\n",
    "# That implementation does something very close to the following:\n",
    "# --z-pres-prior (1 - 1e-15)\n",
    "# --z-pres-prior-raw\n",
    "# --anneal-prior exp\n",
    "# --anneal-prior-to 1e-7\n",
    "# --anneal-prior-begin 1000\n",
    "# --anneal-prior-duration 1e6\n",
    "\n",
    "# e.g. After 200K steps z_pres_p will have decayed to ~0.04\n",
    "\n",
    "# These compute the value of a decaying value at time t.\n",
    "# initial: initial value\n",
    "# final: final value, reached after begin + duration steps\n",
    "# begin: number of steps before decay begins\n",
    "# duration: number of steps over which decay occurs\n",
    "# t: current time step\n",
    "\n",
    "\n",
    "def lin_decay(initial, final, begin, duration, t):\n",
    "    assert duration > 0\n",
    "    x = (final - initial) * (t - begin) / duration + initial\n",
    "    return max(min(x, initial), final)\n",
    "\n",
    "\n",
    "def exp_decay(initial, final, begin, duration, t):\n",
    "    assert final > 0\n",
    "    assert duration > 0\n",
    "    # half_life = math.log(2) / math.log(initial / final) * duration\n",
    "    decay_rate = math.log(initial / final) / duration\n",
    "    x = initial * math.exp(-decay_rate * (t - begin))\n",
    "    return max(min(x, initial), final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreTrueAction(option_strings=['-v', '--verbose'], dest='verbose', nargs=0, const=True, default=False, type=None, choices=None, help='write hyper parameters and network architecture to stdout', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Pyro AIR example\", argument_default=argparse.SUPPRESS)\n",
    "parser.add_argument('-n', '--num-steps', type=int, default=int(1e8),\n",
    "                    help='number of optimization steps to take')\n",
    "parser.add_argument('-b', '--batch-size', type=int, default=64,\n",
    "                    help='batch size')\n",
    "parser.add_argument('-lr', '--learning-rate', type=float, default=1e-4,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('-blr', '--baseline-learning-rate', type=float, default=1e-3,\n",
    "                    help='baseline learning rate')\n",
    "parser.add_argument('--progress-every', type=int, default=1,\n",
    "                    help='number of steps between writing progress to stdout')\n",
    "parser.add_argument('--eval-every', type=int, default=0,\n",
    "                    help='number of steps between evaluations')\n",
    "parser.add_argument('--baseline-scalar', type=float,\n",
    "                    help='scale the output of the baseline nets by this value')\n",
    "parser.add_argument('--no-baselines', action='store_true', default=False,\n",
    "                    help='do not use data dependent baselines')\n",
    "parser.add_argument('--encoder-net', type=int, nargs='+', default=[200],\n",
    "                    help='encoder net hidden layer sizes')\n",
    "parser.add_argument('--decoder-net', type=int, nargs='+', default=[200],\n",
    "                    help='decoder net hidden layer sizes')\n",
    "parser.add_argument('--predict-net', type=int, nargs='+',\n",
    "                    help='predict net hidden layer sizes')\n",
    "parser.add_argument('--embed-net', type=int, nargs='+',\n",
    "                    help='embed net architecture')\n",
    "parser.add_argument('--bl-predict-net', type=int, nargs='+',\n",
    "                    help='baseline predict net hidden layer sizes')\n",
    "parser.add_argument('--non-linearity', type=str,\n",
    "                    help='non linearity to use throughout')\n",
    "parser.add_argument('--viz', action='store_true', default=True,\n",
    "                    help='generate vizualizations during optimization')\n",
    "parser.add_argument('--viz-every', type=int, default=100,\n",
    "                    help='number of steps between vizualizations')\n",
    "parser.add_argument('--visdom-env', default='main',\n",
    "                    help='visdom enviroment name')\n",
    "parser.add_argument('--load', type=str, default=\"/Users/chamathabeysinghe/Projects/monash/test/variational_auto_encoder/checkpoints/model-size-75-3ants.ckpt\",\n",
    "                    help='load previously saved parameters')\n",
    "parser.add_argument('--save', type=str, default=\"/Users/chamathabeysinghe/Projects/monash/test/variational_auto_encoder/checkpoints/model-size-75-3ants.ckpt\",\n",
    "                    help='save parameters to specified file')\n",
    "parser.add_argument('--save-every', type=int, default=100,\n",
    "                    help='number of steps between parameter saves')\n",
    "parser.add_argument('--cuda', action='store_true', default=False,\n",
    "                    help='use cuda')\n",
    "parser.add_argument('--jit', action='store_true', default=False,\n",
    "                    help='use PyTorch jit')\n",
    "parser.add_argument('-t', '--model-steps', type=int, default=3,\n",
    "                    help='number of time steps')\n",
    "parser.add_argument('--rnn-hidden-size', type=int, default=256,\n",
    "                    help='rnn hidden size')\n",
    "parser.add_argument('--encoder-latent-size', type=int, default=50,\n",
    "                    help='attention window encoder/decoder latent space size')\n",
    "parser.add_argument('--decoder-output-bias', type=float,\n",
    "                    help='bias added to decoder output (prior to applying non-linearity)')\n",
    "parser.add_argument('--decoder-output-use-sigmoid', action='store_true',\n",
    "                    help='apply sigmoid function to output of decoder network')\n",
    "parser.add_argument('--window-size', type=int, default=28,\n",
    "                    help='attention window size')\n",
    "parser.add_argument('--z-pres-prior', type=float, default=0.5,\n",
    "                    help='prior success probability for z_pres')\n",
    "parser.add_argument('--z-pres-prior-raw', action='store_true', default=False,\n",
    "                    help='use --z-pres-prior directly as success prob instead of a geometric like prior')\n",
    "parser.add_argument('--anneal-prior', choices='none lin exp'.split(), default='none',\n",
    "                    help='anneal z_pres prior during optimization')\n",
    "parser.add_argument('--anneal-prior-to', type=float, default=1e-7,\n",
    "                    help='target z_pres prior prob')\n",
    "parser.add_argument('--anneal-prior-begin', type=int, default=0,\n",
    "                    help='number of steps to wait before beginning to anneal the prior')\n",
    "parser.add_argument('--anneal-prior-duration', type=int, default=100000,\n",
    "                    help='number of steps over which to anneal the prior')\n",
    "parser.add_argument('--pos-prior-mean', type=float,\n",
    "                    help='mean of the window position prior')\n",
    "parser.add_argument('--pos-prior-sd', type=float,\n",
    "                    help='std. dev. of the window position prior')\n",
    "parser.add_argument('--scale-prior-mean', type=float,\n",
    "                    help='mean of the window scale prior')\n",
    "parser.add_argument('--scale-prior-sd', type=float,\n",
    "                    help='std. dev. of the window scale prior')\n",
    "parser.add_argument('--no-masking', action='store_true', default=False,\n",
    "                    help='do not mask out the costs of unused choices')\n",
    "parser.add_argument('--seed', type=int, help='random seed', default=None)\n",
    "parser.add_argument('-v', '--verbose', action='store_true', default=False,\n",
    "                    help='write hyper parameters and network architecture to stdout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars(parser.parse_args(\"\"))\n",
    "args = argparse.Namespace(**vars(parser.parse_args(\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if 'save' in args:\n",
    "#     if os.path.exists(args.save):\n",
    "#         raise RuntimeError('Output file \"{}\" already exists.'.format(args.save))\n",
    "\n",
    "if args.seed is not None:\n",
    "    pyro.set_rng_seed(args.seed)\n",
    "\n",
    "# Build a function to compute z_pres prior probabilities.\n",
    "if args.z_pres_prior_raw:\n",
    "    def base_z_pres_prior_p(t):\n",
    "        return args.z_pres_prior\n",
    "else:\n",
    "    base_z_pres_prior_p = make_prior(args.z_pres_prior)\n",
    "\n",
    "# Wrap with logic to apply any annealing.\n",
    "def z_pres_prior_p(opt_step, time_step):\n",
    "    p = base_z_pres_prior_p(time_step)\n",
    "    if args.anneal_prior == 'none':\n",
    "        return p\n",
    "    else:\n",
    "        decay = dict(lin=lin_decay, exp=exp_decay)[args.anneal_prior]\n",
    "        return decay(p, args.anneal_prior_to, args.anneal_prior_begin,\n",
    "                     args.anneal_prior_duration, opt_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "#     inpath = './air/.data'\n",
    "#     X_np, Y = multi_mnist.load(inpath)\n",
    "    X_np = np.load('/Users/chamathabeysinghe/Projects/monash/test/variational_auto_encoder/data/ANTS-SYNTHETIC/original: 300-resize: 75-3ants.npy')\n",
    "    X_np = X_np.astype(np.float32)\n",
    "    X_np /= 255.0\n",
    "    X = torch.from_numpy(X_np)\n",
    "    # Using FloatTensor to allow comparison with values sampled from\n",
    "    # Bernoulli.\n",
    "    counts = torch.FloatTensor([1 for objs in X_np])\n",
    "    return X, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     X_np = np.load('/Users/chamathabeysinghe/Projects/monash/test/variational_auto_encoder/data/synthetic/size-50_rad-5.npy')\n",
    "\n",
    "X, true_counts = load_data()\n",
    "X_size = X.size(0)\n",
    "if args.cuda:\n",
    "    X = X.cuda()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n",
    "# plot_mnist_sample(X[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "    plot_mnist_sample(X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arg_keys = ['window_size',\n",
    "                  'rnn_hidden_size',\n",
    "                  'decoder_output_bias',\n",
    "                  'decoder_output_use_sigmoid',\n",
    "                  'baseline_scalar',\n",
    "                  'encoder_net',\n",
    "                  'decoder_net',\n",
    "                  'predict_net',\n",
    "                  'embed_net',\n",
    "                  'bl_predict_net',\n",
    "                  'non_linearity',\n",
    "                  'pos_prior_mean',\n",
    "                  'pos_prior_sd',\n",
    "                  'scale_prior_mean',\n",
    "                  'scale_prior_sd']\n",
    "model_args = {key: getattr(args, key) for key in model_arg_keys if key in args}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "air = AIR(\n",
    "        num_steps=args.model_steps,\n",
    "        x_size=75,\n",
    "        use_masking=not args.no_masking,\n",
    "        use_baselines=not args.no_baselines,\n",
    "        z_what_size=args.encoder_latent_size,\n",
    "        use_cuda=args.cuda,\n",
    "        **model_args\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'load' in args:\n",
    "    print('Loading parameters...')\n",
    "    air.load_state_dict(torch.load(args.load))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if args.viz:\n",
    "    vis = visdom.Visdom(env=args.visdom_env)\n",
    "    z, x = air.prior(5, z_pres_prior_p=partial(z_pres_prior_p, 0))\n",
    "    vis.images(draw_many(x, tensor_to_objs(latents_to_tensor(z))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isBaselineParam(module_name, param_name):\n",
    "    return 'bl_' in module_name or 'bl_' in param_name\n",
    "\n",
    "def per_param_optim_args(module_name, param_name):\n",
    "    lr = args.baseline_learning_rate if isBaselineParam(module_name, param_name) else args.learning_rate\n",
    "    return {'lr': lr}\n",
    "\n",
    "adam = optim.Adam(per_param_optim_args)\n",
    "elbo = JitTraceGraph_ELBO() if args.jit else TraceGraph_ELBO()\n",
    "svi = SVI(air.model, air.guide, adam, loss=elbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "examples_to_viz = X[5:10]\n",
    "\n",
    "for i in range(1, args.num_steps + 1):\n",
    "\n",
    "    loss = svi.step(X, batch_size=args.batch_size, z_pres_prior_p=partial(z_pres_prior_p, i))\n",
    "\n",
    "    if args.progress_every > 0 and i % args.progress_every == 0:\n",
    "        print('i={}, epochs={:.2f}, elapsed={:.2f}, elbo={:.2f}'.format(\n",
    "            i,\n",
    "            (i * args.batch_size) / X_size,\n",
    "            (time.time() - t0) / 3600,\n",
    "            loss / X_size))\n",
    "\n",
    "    if args.viz and i % args.viz_every == 0:\n",
    "        print('Drawing')\n",
    "        trace = poutine.trace(air.guide).get_trace(examples_to_viz, None)\n",
    "        z, recons = poutine.replay(air.prior, trace=trace)(examples_to_viz.size(0))\n",
    "        z_wheres = tensor_to_objs(latents_to_tensor(z))\n",
    "\n",
    "        # Show data with inferred objection positions.\n",
    "        vis.images(draw_many(examples_to_viz, z_wheres))\n",
    "        # Show reconstructions of data.\n",
    "        vis.images(draw_many(recons, z_wheres))\n",
    "\n",
    "    if args.eval_every > 0 and i % args.eval_every == 0:\n",
    "        # Measure accuracy on subset of training data.\n",
    "        acc, counts, error_z, error_ix = count_accuracy(X, true_counts, air, 1000)\n",
    "        print('i={}, accuracy={}, counts={}'.format(i, acc, counts.numpy().tolist()))\n",
    "        if args.viz and error_ix.size(0) > 0:\n",
    "            vis.images(draw_many(X[error_ix[0:5]], tensor_to_objs(error_z[0:5])),\n",
    "                       opts=dict(caption='errors ({})'.format(i)))\n",
    "\n",
    "    if 'save' in args and i % args.save_every == 0:\n",
    "        print('Saving parameters...')\n",
    "        torch.save(air.state_dict(), args.save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples_to_viz = X[0:50]\n",
    "trace = poutine.trace(air.guide).get_trace(examples_to_viz, None)\n",
    "z, recons = poutine.replay(air.prior, trace=trace)(examples_to_viz.size(0))\n",
    "z_wheres = tensor_to_objs(latents_to_tensor(z))\n",
    "\n",
    "# Show data with inferred objection positions.\n",
    "vis.images(draw_many(examples_to_viz, z_wheres))\n",
    "# Show reconstructions of data.\n",
    "vis.images(draw_many(recons, z_wheres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    print(sum(z.pres for z in z_wheres[i]))\n",
    "    predictions.append(int(sum(z.pres for z in z_wheres[i]).item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative_count = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    if (predictions[i]<i%3):\n",
    "        false_negative_count += 1\n",
    "        print(\"Expected: {} Predicted:{}\".format(i%4, predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negative_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.images(draw_many(X[error_ix[10:20]], tensor_to_objs(error_z[10:20])),\n",
    "                       opts=dict(caption='errors ({})'.format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50):\n",
    "    print(len(z_wheres[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch",
   "language": "python",
   "name": "venv_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}